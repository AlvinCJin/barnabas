== Apache Zookeeper

Apache Kafka is using Apache Zookeeper to store configuration data as well as for cluster coordination (e.g. leader
election). To start and run Kafka broker, Zookeeper needs to be installed and available.

=== Installation on Linux

==== Prerequisites

Zookeeper requires following components to be installed:

* JRE 8

==== Installation procedure

Zookeeper can be installed using following installation procedure:

. Add new `zookeeper` user and group:
+
[source]
----
sudo groupadd zookeeper
sudo useradd -g zookeeper zookeeper
sudo passwd zookeeper
----
. Create directory `/opt/zookeeper` and set its ownership to the `zookeeper` user:
+
[source]
----
sudo mkdir /opt/zookeeper
sudo chown -R zookeeper:zookeeper /opt/zookeeper
----
. Download the latest stable version from Apache Zookeeper http://zookeeper.apache.org/releases.html[download website]
. Change the ownership of the downloaded archive and move it to the newly created directory
(replace `x.x.x` for the downloaded version of Zookeeper - e.g. `3.4.11`):
+
[source]
----
sudo chown -R zookeeper:zookeeper zookeeper-x.x.x.tar.gz
sudo mv zookeeper-x.x.x.tar.gz /opt/zookeeper
----
. Unpack the archive and delete it (replace `x.x.x` for the downloaded version of Zookeeper - e.g. `3.4.11`)
+
[source]
----
su - zookeeper
cd /opt/zookeeper
tar xvfz zookeeper-x.x.x.tar.gz -C /opt/zookeeper --strip-components=1
rm zookeeper-x.x.x.tar.gz
----
. Create directory `/var/lib/zookeeper` for storing Zookeeper data and set its ownership to the `zookeeper` user:
+
[source]
----
sudo mkdir /var/lib/zookeeper
sudo chown -R zookeeper:zookeeper /var/lib/zookeeper
----

=== Standalone configuration

Zookeper can run in a standalone mode with only a single instance. However since Kafka broker is fully dependent on
Zookeeper it will stop working almost immediately when the single Zookeeper instance becomes unavailable. Therefore the
standalone configuration is not recommended for production use cases.

Zookeeper is using properties file for configuration. The most important configuration options are:

`tickTime`:: Zookeeper's basic time unit (in milliseconds) used for heartbeats and session timeouts.
`dataDir`:: The directory where Zookeeper data are stored. Should be set to `/var/lib/zookeeper/` directory created
during installation.
`clientPort`:: Port number where clients can connect. Defaults to `2181`.

NOTE: The sample configuration file can be found in `conf/zoo_sample.cfg` in the Zookeeper installation directory.

Zookeeper configuration file should be located in `/opt/zookeeper/cong/zoo.cfg`. A basic example of the configuration
file can be found below. The configuration file should be owned by the `zookeeper` user.

[source]
----
timeTick=2000
dataDir=/var/lib/zookeeper/
clientPort=2181
----

Once the configuration file is prepared, Zookeeper can be started using following command. In case the configuration
file is not located in `/opt/zookeeper/cong/zoo.cfg` the command has to be adapted accordingly.

[source]
----
su - zookeeper
/opt/zookeeper/bin/zkServer.sh start conf/zoo.cfg
----

To stop running Zookeeper instance following command can be used:
[source]
----
su - zookeeper
/opt/zookeeper/bin/zkServer.sh stop conf/zoo.cfg
----

To restart running Zookeeper instance following command can be used:
[source]
----
su - zookeeper
/opt/zookeeper/bin/zkServer.sh stop conf/zoo.cfg
----

=== Replicated configuration

For production use cases it is strongly recommended to run a cluster of replicated Zookeeper instances.

TIP: Zookeeper clusters are sometimes also refer to as _ensembles_.

Zookeeper clusters usually consist of odd number of nodes. Zookeeper requires majority of cluster nodes to be available
to work. For example a cluster with 3 nodes requires at least 2 of them to be up and running. In other words it can
tolerate 1 node being down. Cluster consisting of 5 nodes requires at least 3 nodes to be available. In other words it
can tolerate 2 nodes being down.

TIP: Zookeeper can run in clusters with even number of nodes. The additional node however doesn't increase the
resiliency of the cluster. A cluster with 4 nodes requires at least 3 nodes to be available and can tolerate only 1 node
being down. Therefore it has exactly the same resiliency as a cluster with only 3 nodes.

The different Zookeeper nodes should be ideally placed into different data centers or network segments. Increasing the
number of Zookeeper nodes increases the workload spent on cluster synchronization. For most Kafka use cases Zookeeper
cluster with 3, 5 or 7 nodes should be fully sufficient.

Replicated Zookeeper configuration supports all configuration options supported by the standalone configuration.
Additional options are added for the cluster configuration:

`initLimit`:: Amount of time to allow followers to connect and sync to the cluster leader. The time is specified as
number of ticks (see the `timeTick` potion for more details).
`syncLimit`:: Amount of time for which followers can be behind the leader. The time is specified as number of ticks
(see the `timeTick` potion for more details).

In addition to the options above, every configuration file should contain a lost of servers which should be members of
the Zookeeper cluster. The server records should be specified in the format `server.id=hostname:port1:port2`, where:

`id`:: is the ID of the Zookeeper cluster node.
`hostname`:: is the hostname or IP address where the node listens for connections.
`port1`:: is the number of the port used for intercluster communication.
`port2`:: is the bumber of the port used for leader election.

Following example shows how the configuration file for Zookeeper cluster might look like:

[source]
----
timeTick=2000
dataDir=/var/lib/zookeeper/
clientPort=2181
initLimit=5
syncLimit=2

server.1=172.17.0.1:2888:3888
server.2=172.17.0.2:2888:3888
server.3=172.17.0.3:2888:3888
----

Each node in the Zookeeper cluster has to be assigned an `ID`. Node `ID` is configured in a file named `myid` which has
to be stored in the `dataDir` folder (e.g. `/var/lib/zookeeper/`). The `myid` files should contain only a single line
with the `ID` written as text. The `ID` can be any integer from 1 to 255. The `ID` has to be unique within the Zookeeper
cluster. This file has to be created manually on each
cluster node. Using this file, given Zookeeper instance will use the configuration from the corresponding line in the
configuration file to configure its listeners and use all other lines to identify other cluster members.

Once the configuration files are prepared, the individual cluster nodes should be started in the same way as standalone
Zookeeper instance.

==== Procedure

Follow this procedure *on each node* to start replicated Zookeeper cluster:

. Create the `myid` file as described above.
. Create the configuration file with list of all cluster members as described above.
. Start the instance using:
+
[source]
----
su - zookeeper
/opt/zookeeper/bin/zkServer.sh start conf/zoo.cfg
----

=== Additional configuration options

Following options should be consider depending on the exact usecase scenario:

`maxClientCnxns`:: Maximal number of simultaneously connected clients.
`autopurge.snapRetainCount`:: Number of data snapshots which will be retained. Default value is `3`.
`autopurge.purgeInterval`:: Interval in hours for puring snapshots. Default value is `0` (auto-purging disabled).

All available configuration options can be found in Apache Zookeeper
http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance[documentation].

=== Security

==== SASL Authentication

By default Zookeeper doesn't use any form of authentication and allows anonymous connections. However it supports Java
Authentication and Authorization Service (JAAS) which can be used to setup authentication using Simple Authentication
and Security Layer (SASL). Zookeeper supports authentication using DIGEST-MD5 SASL mechanism with locally stored
credentials or authentication using Kerberos.

JAAS is configured using a separate configuration file. It is recommended to place the JAAS configuration file in the
same directory as the Zookeeper configuration (`/opt/zookeeper/cong/`). The recommended file name is `jaas.conf`. When
using Zookeeper cluster, the JAAS configuration file has to be created on all cluster nodes.

SASL Authentication is configured separately for server to server communication (communication between Zookeeper
instances) ad client to server communication (e.g. communication between Kafka and Zookeeper). The server to server
authentication is relevant only for resilient Zookeeper clusters with multiple nodes.

===== Server to Server authentication

For server to server authentication the JAAS configuration file contains both parts: the server configuration as well as the
client configuration. Each part fo the configuration has its own _context_. The context is configuration has following
format:

[source]
----
ContextName {
       param1
       param2;
};
----

When using DIGEST-MD5 SASL mechanism the `QuorumServer` context needs to contain all the usernames and passwords in
unencrypted form which will be allowed to connect. Second context `QuorumLearner` has to be configured to configure the
client which is built into Zookeeper. It again contains the password in unencrypted form. An example of the JAAS
configuration file for DIGEST-MD5 mechanism can be found below:

[source]
----
QuorumServer {
       org.apache.zookeeper.server.auth.DigestLoginModule required
       user_zookeeper="123456";
};

QuorumLearner {
       org.apache.zookeeper.server.auth.DigestLoginModule required
       username="zookeeper"
       password="123456";
};
----

Alternatively Kerberos based authentication can be configured as well. Detailed guide for configuring Kerberos
authentication is beyond the scope of this document.

[source]
----
QuorumServer {
       com.sun.security.auth.module.Krb5LoginModule required
       useKeyTab=true
       keyTab="/path/to/keytab"
       storeKey=true
       useTicketCache=false
       debug=false
       principal="zkquorum/fully.qualified.domain.name@EXAMPLE.COM";
};

QuorumLearner {
       com.sun.security.auth.module.Krb5LoginModule required
       useKeyTab=true
       keyTab="/path/to/keytab"
       storeKey=true
       useTicketCache=false
       debug=false
       principal="learner/fully.qualified.domain.name@EXAMPLE.COM";
};
----

In addition to the JAAS configuration file the server to server authentication needs to be also enabled in the regular
Zookeeper configuration file. To enable it add following options:

[source]
----
quorum.auth.enableSasl=true
quorum.auth.learnerRequireSasl=true
quorum.auth.serverRequireSasl=true
quorum.auth.learner.loginContext=QuorumLearner
quorum.auth.server.loginContext=QuorumServer
quorum.cnxn.threads.size=20
----

Additionally, if Kerberos authentication is used the _Kerberos service principal_ has to be specified:

[source]
----
quorum.auth.kerberos.servicePrincipal=servicename/_HOST
----

The JAAS configuration file has to be passed to the Zookeeper server as Java property. Environment variable
`SERVER_JVMFLAGS` can be used for that:

[source]
----
su - zookeeper
SERVER_JVMFLAGS="-Djava.security.auth.login.config=/opt/zookeeper/conf/jaas.conf"; /opt/zookeeper/bin/zkServer.sh start conf/zoo.cfg
----

More details about server to server authentication can be found on the Zookeeper
https://cwiki.apache.org/confluence/display/ZOOKEEPER/Server-Server+mutual+authentication[wiki].

===== Client to Server authentication

Client to server authentication is configured in the same JAAS file as the server to server authentication. However
unlike the server to server authentication it contains only the server part. The client part of the configuration has
to be done in the client. How to configure Kafka broker to connect to Zookeeper using authentication is described in the
Kafka installation part of this guide.

Another context has to be added to the JAAS configuration file to configure client to server authentication. This
context has to be named `Server`. For DIGEST-MD5 mechanism it configures all usernames and password:

[source]
----
Server {
    org.apache.zookeeper.server.auth.DigestLoginModule required
    user_super="123456"
    user_kafka="123456";
};
----

It is also possible to enable authentication using Kerberos:
[source]
----
Server {
       com.sun.security.auth.module.Krb5LoginModule required
       useKeyTab=true
       keyTab="/path/to/server/keytab"
       storeKey=true
       useTicketCache=false
       principal="zookeeper/yourzkhostname";
};
----

After configuring the JAAS context, client to server authentication needs to be enabled in the Zookeeper configuration
file. To enable it following lines should be added:

[source]
----
requireClientAuthScheme=sasl
authProvider.1=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
authProvider.2=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
authProvider.3=org.apache.zookeeper.server.auth.SASLAuthenticationProvider
----

The `authProvider.ID` property has to be added for every server which is part of the Zookeeper cluster.

The JAAS configuration file has to be passed to the Zookeeper server as Java property. Environment variable
`SERVER_JVMFLAGS` can be used for that:

[source]
----
su - zookeeper
SERVER_JVMFLAGS="-Djava.security.auth.login.config=/opt/zookeeper/conf/jaas.conf"; /opt/zookeeper/bin/zkServer.sh start conf/zoo.cfg
----

More details about client to server authentication can be found on the Zookeeper
https://cwiki.apache.org/confluence/display/ZOOKEEPER/Client-Server+mutual+authentication[wiki].

==== ACL Authorization

Zookeeper supports ACL rights to protect data stroed inside it. Apache Kafka can automatically configure the ACL rights
for all Zookeeper records it creates so that nobody else can modify them. For more details see the Kafka installation
part of this guide

==== TLS

The latest version of Zookeeper currently doesn't support TLS for encryption or authentication.